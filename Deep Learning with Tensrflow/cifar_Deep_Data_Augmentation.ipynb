{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, regularizers, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=50\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    " \n",
    "    #normalize \n",
    "    mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "    std = np.std(x_train,axis=(0,1,2,3))\n",
    "    x_train = (x_train-mean)/(std+1e-7)\n",
    "    x_test = (x_test-mean)/(std+1e-7)\n",
    " \n",
    "    y_train =  tf.keras.utils.to_categorical(y_train,NUM_CLASSES)\n",
    "    y_test =  tf.keras.utils.to_categorical(y_test,NUM_CLASSES)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    #1st blocl\n",
    "    model.add(layers.Conv2D(32, (3,3), padding='same', input_shape=x_train.shape[1:], activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    #2nd block\n",
    "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    #3d block \n",
    "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "\n",
    "    #dense  \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train, x_test, y_test) = load_data()\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "            optimizer='RMSprop', \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_34152\\326942008.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 23s 25ms/step - loss: 2.1095 - accuracy: 0.3638 - val_loss: 1.6072 - val_accuracy: 0.4907\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 1.5735 - accuracy: 0.4964 - val_loss: 1.2139 - val_accuracy: 0.6081\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.3685 - accuracy: 0.5526 - val_loss: 1.2229 - val_accuracy: 0.6031\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 1.2211 - accuracy: 0.5928 - val_loss: 1.1699 - val_accuracy: 0.6236\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.1003 - accuracy: 0.6204 - val_loss: 1.0336 - val_accuracy: 0.6642\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.0220 - accuracy: 0.6468 - val_loss: 1.0628 - val_accuracy: 0.6617\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.9667 - accuracy: 0.6659 - val_loss: 0.8462 - val_accuracy: 0.7126\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.9189 - accuracy: 0.6829 - val_loss: 0.7843 - val_accuracy: 0.7441\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.8879 - accuracy: 0.6940 - val_loss: 0.7339 - val_accuracy: 0.7513\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 18s 24ms/step - loss: 0.8520 - accuracy: 0.7072 - val_loss: 0.7531 - val_accuracy: 0.7523\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.8284 - accuracy: 0.7141 - val_loss: 0.7270 - val_accuracy: 0.7570\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.8054 - accuracy: 0.7219 - val_loss: 0.6945 - val_accuracy: 0.7713\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 0.7858 - accuracy: 0.7305 - val_loss: 0.7187 - val_accuracy: 0.7679\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.7704 - accuracy: 0.7341 - val_loss: 0.6578 - val_accuracy: 0.7835\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 18s 24ms/step - loss: 0.7544 - accuracy: 0.7397 - val_loss: 0.6210 - val_accuracy: 0.7912\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.7353 - accuracy: 0.7462 - val_loss: 0.7598 - val_accuracy: 0.7616\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.7260 - accuracy: 0.7499 - val_loss: 0.6420 - val_accuracy: 0.7897\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.7080 - accuracy: 0.7548 - val_loss: 0.7157 - val_accuracy: 0.7728\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 0.7025 - accuracy: 0.7567 - val_loss: 0.6973 - val_accuracy: 0.7737\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 0.6843 - accuracy: 0.7645 - val_loss: 0.6486 - val_accuracy: 0.7921\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 18s 24ms/step - loss: 0.6869 - accuracy: 0.7639 - val_loss: 0.6223 - val_accuracy: 0.7976\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.6780 - accuracy: 0.7662 - val_loss: 0.5956 - val_accuracy: 0.8063\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.6689 - accuracy: 0.7699 - val_loss: 0.5903 - val_accuracy: 0.8078\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 18s 24ms/step - loss: 0.6630 - accuracy: 0.7690 - val_loss: 0.5963 - val_accuracy: 0.8088\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.6528 - accuracy: 0.7736 - val_loss: 0.5251 - val_accuracy: 0.8283\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.6467 - accuracy: 0.7760 - val_loss: 0.5811 - val_accuracy: 0.8087\n",
      "Epoch 27/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.6362 - accuracy: 0.7807 - val_loss: 0.5439 - val_accuracy: 0.8261\n",
      "Epoch 28/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.6316 - accuracy: 0.7844 - val_loss: 0.5277 - val_accuracy: 0.8283\n",
      "Epoch 29/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.6274 - accuracy: 0.7832 - val_loss: 0.5819 - val_accuracy: 0.8120\n",
      "Epoch 30/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.6172 - accuracy: 0.7895 - val_loss: 0.5086 - val_accuracy: 0.8356\n",
      "Epoch 31/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.6182 - accuracy: 0.7887 - val_loss: 0.6295 - val_accuracy: 0.8039\n",
      "Epoch 32/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.6165 - accuracy: 0.7877 - val_loss: 0.6568 - val_accuracy: 0.7927\n",
      "Epoch 33/50\n",
      "782/782 [==============================] - 18s 24ms/step - loss: 0.6088 - accuracy: 0.7911 - val_loss: 0.5659 - val_accuracy: 0.8231\n",
      "Epoch 34/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.6032 - accuracy: 0.7924 - val_loss: 0.5030 - val_accuracy: 0.8355\n",
      "Epoch 35/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5917 - accuracy: 0.7955 - val_loss: 0.5166 - val_accuracy: 0.8347\n",
      "Epoch 36/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5985 - accuracy: 0.7943 - val_loss: 0.5809 - val_accuracy: 0.8232\n",
      "Epoch 37/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.5882 - accuracy: 0.8002 - val_loss: 0.4944 - val_accuracy: 0.8419\n",
      "Epoch 38/50\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.5902 - accuracy: 0.7972 - val_loss: 0.4782 - val_accuracy: 0.8433\n",
      "Epoch 39/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.5847 - accuracy: 0.7981 - val_loss: 0.5000 - val_accuracy: 0.8373\n",
      "Epoch 40/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5728 - accuracy: 0.8019 - val_loss: 0.5752 - val_accuracy: 0.8242\n",
      "Epoch 41/50\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 0.5797 - accuracy: 0.8002 - val_loss: 0.5504 - val_accuracy: 0.8293\n",
      "Epoch 42/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.5753 - accuracy: 0.8023 - val_loss: 0.5493 - val_accuracy: 0.8279\n",
      "Epoch 43/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5713 - accuracy: 0.8043 - val_loss: 0.5543 - val_accuracy: 0.8234\n",
      "Epoch 44/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5715 - accuracy: 0.8042 - val_loss: 0.5588 - val_accuracy: 0.8250\n",
      "Epoch 45/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5634 - accuracy: 0.8064 - val_loss: 0.5704 - val_accuracy: 0.8254\n",
      "Epoch 46/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5619 - accuracy: 0.8073 - val_loss: 0.4777 - val_accuracy: 0.8453\n",
      "Epoch 47/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5612 - accuracy: 0.8056 - val_loss: 0.4999 - val_accuracy: 0.8422\n",
      "Epoch 48/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5580 - accuracy: 0.8096 - val_loss: 0.5386 - val_accuracy: 0.8262\n",
      "Epoch 49/50\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.5569 - accuracy: 0.8086 - val_loss: 0.4839 - val_accuracy: 0.8448\n",
      "Epoch 50/50\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.5534 - accuracy: 0.8093 - val_loss: 0.4991 - val_accuracy: 0.8403\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.4991 - accuracy: 0.8403\n",
      "\n",
      "Test result: 84.030 loss: 0.499\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "batch_size = 64\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1,validation_data=(x_test,y_test))\n",
    "#save to disk\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model.h5') \n",
    "\n",
    "#test\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74cb3f0fa9d33bfcf8189af548fbb183ee6c25feac19421c4a86f6e6cba68299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
